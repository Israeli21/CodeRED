{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b0d5906",
   "metadata": {},
   "source": [
    "# Wind Energy Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdfea07-0861-4273-92f3-8bdfc78cda07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to download turbine data (attempt 1/3)...\n",
      "‚úó Error: HTTP Error 503: Service Unavailable\n",
      "  Waiting 1 seconds before retry...\n",
      "Attempting to download turbine data (attempt 2/3)...\n",
      "‚úó Error: HTTP Error 503: Service Unavailable\n",
      "  Waiting 2 seconds before retry...\n",
      "Attempting to download turbine data (attempt 3/3)...\n",
      "‚úó Error: HTTP Error 503: Service Unavailable\n",
      "  Server unavailable. Using sample data instead...\n",
      "\n",
      "üìä Creating sample turbine dataset for demonstration...\n",
      "‚úì Sample dataset created with 100 turbines\n",
      "\n",
      "üå¨Ô∏è  Fetching wind data...\n",
      "‚ö†Ô∏è  NREL API unavailable - using synthetic wind data for demonstration\n",
      "  Progress: 10/50 turbines processed\n",
      "  Progress: 20/50 turbines processed\n",
      "  Progress: 30/50 turbines processed\n",
      "  Progress: 40/50 turbines processed\n",
      "  Progress: 50/50 turbines processed\n",
      "‚úì Wind features generated for 50 turbines\n",
      "\n",
      "ü§ñ Training Random Forest model...\n",
      "‚úì Model trained successfully!\n",
      "  R¬≤ score on test set: 0.9882\n",
      "\n",
      "üéØ Predicting power potential for candidate site (Texas)...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- dominant_dir\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 174\u001b[0m\n\u001b[0;32m    168\u001b[0m         candidate \u001b[38;5;241m=\u001b[39m generate_synthetic_wind_features(candidate_lat, candidate_lon)\n\u001b[0;32m    170\u001b[0m X_new \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([{\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcandidate,\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnearest_turbine_km\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m20\u001b[39m  \u001b[38;5;66;03m# assume sparse area\u001b[39;00m\n\u001b[0;32m    173\u001b[0m }])\n\u001b[1;32m--> 174\u001b[0m pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_new)\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úì Predicted power potential: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpred[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (m¬≥/s¬≥)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Wind speed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcandidate[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_ws\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m m/s\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\isrtr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:1065\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1063\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1064\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m-> 1065\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X)\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32mc:\\Users\\isrtr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:637\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    635\u001b[0m     ensure_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 637\u001b[0m X \u001b[38;5;241m=\u001b[39m validate_data(\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    639\u001b[0m     X,\n\u001b[0;32m    640\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mDTYPE,\n\u001b[0;32m    641\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    642\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    643\u001b[0m     ensure_all_finite\u001b[38;5;241m=\u001b[39mensure_all_finite,\n\u001b[0;32m    644\u001b[0m )\n\u001b[0;32m    645\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\isrtr\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2929\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2845\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_data\u001b[39m(\n\u001b[0;32m   2846\u001b[0m     _estimator,\n\u001b[0;32m   2847\u001b[0m     \u001b[38;5;241m/\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2853\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m   2854\u001b[0m ):\n\u001b[0;32m   2855\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[0;32m   2856\u001b[0m \n\u001b[0;32m   2857\u001b[0m \u001b[38;5;124;03m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2927\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m   2928\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2929\u001b[0m     _check_feature_names(_estimator, X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m   2930\u001b[0m     tags \u001b[38;5;241m=\u001b[39m get_tags(_estimator)\n\u001b[0;32m   2931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mtarget_tags\u001b[38;5;241m.\u001b[39mrequired:\n",
      "File \u001b[1;32mc:\\Users\\isrtr\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2787\u001b[0m, in \u001b[0;36m_check_feature_names\u001b[1;34m(estimator, X, reset)\u001b[0m\n\u001b[0;32m   2784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m   2785\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 2787\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- dominant_dir\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests, io\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from geopy.distance import distance\n",
    "\n",
    "# 1Ô∏è‚É£ Load turbine database (labels + coordinates)\n",
    "# Try to load from USGS with retry logic\n",
    "url = \"https://eersc.usgs.gov/uswtdb/data/USWTDB_V8_1_20250527/USWTDB_v8_1_20250527.csv\"\n",
    "max_retries = 3\n",
    "turbines = None\n",
    "\n",
    "for attempt in range(max_retries):\n",
    "    try:\n",
    "        print(f\"Attempting to download turbine data (attempt {attempt + 1}/{max_retries})...\")\n",
    "        turbines = pd.read_csv(url)\n",
    "        print(\"‚úì Successfully loaded turbine database!\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Error: {e}\")\n",
    "        if attempt < max_retries - 1:\n",
    "            wait_time = 2 ** attempt\n",
    "            print(f\"  Waiting {wait_time} seconds before retry...\")\n",
    "            time.sleep(wait_time)\n",
    "        else:\n",
    "            print(\"  Server unavailable. Using sample data instead...\")\n",
    "\n",
    "# Fallback: Use sample data if download fails\n",
    "if turbines is None:\n",
    "    print(\"\\nüìä Creating sample turbine dataset for demonstration...\")\n",
    "    np.random.seed(42)\n",
    "    turbines = pd.DataFrame({\n",
    "        'ylat': np.random.uniform(25, 49, 100),  # US latitudes\n",
    "        'xlong': np.random.uniform(-125, -65, 100),  # US longitudes\n",
    "        't_cap': np.random.uniform(1.5, 3.5, 100),  # turbine capacity (MW)\n",
    "        't_hh': np.random.uniform(80, 120, 100),  # hub height (m)\n",
    "        't_rd': np.random.uniform(40, 60, 100),  # rotor diameter (m)\n",
    "        'p_year': np.random.randint(2010, 2024, 100)  # year\n",
    "    })\n",
    "    print(\"‚úì Sample dataset created with 100 turbines\")\n",
    "\n",
    "turbines = turbines[['ylat','xlong','t_cap','t_hh','t_rd','p_year']].dropna()\n",
    "\n",
    "# 2Ô∏è‚É£ Sample subset for faster demo\n",
    "turbines = turbines.sample(50, random_state=0).reset_index(drop=True)\n",
    "\n",
    "# 3Ô∏è‚É£ Query NREL WIND Toolkit for each turbine site\n",
    "def get_wind_features(lat, lon, api_key):\n",
    "    \"\"\"Fetch real wind data from NREL API\"\"\"\n",
    "    url = \"https://developer.nrel.gov/api/wind-toolkit/v2/wind/wtk-download.csv\"\n",
    "    params = {\n",
    "        \"api_key\": api_key,\n",
    "        \"lat\": lat,\n",
    "        \"lon\": lon,\n",
    "        \"names\": 2014,\n",
    "        \"hubheight\": 100,\n",
    "        \"timestep\": 60,\n",
    "        \"attributes\": \"wind_speed,wind_direction,temperature\"\n",
    "    }\n",
    "    try:\n",
    "        r = requests.get(url, params=params, timeout=10)\n",
    "        if r.status_code != 200:\n",
    "            return None\n",
    "        df = pd.read_csv(io.StringIO(r.text))\n",
    "        # aggregate features\n",
    "        return {\n",
    "            \"mean_ws\": df[\"wind_speed\"].mean(),\n",
    "            \"std_ws\": df[\"wind_speed\"].std(),\n",
    "            \"max_ws\": df[\"wind_speed\"].max(),\n",
    "            \"mean_temp\": df[\"temperature\"].mean(),\n",
    "            \"dominant_dir\": df[\"wind_direction\"].mode()[0]\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def generate_synthetic_wind_features(lat, lon):\n",
    "    \"\"\"Generate realistic synthetic wind data based on location\"\"\"\n",
    "    # Wind speed generally increases with latitude and decreases with longitude in US\n",
    "    # Add some randomness for realism\n",
    "    np.random.seed(int(abs(lat * 1000 + lon * 1000)) % 2**32)\n",
    "    base_wind = 6 + (abs(lat - 35) / 10) + np.random.normal(0, 1)\n",
    "    \n",
    "    return {\n",
    "        \"mean_ws\": max(4.0, min(12.0, base_wind)),\n",
    "        \"std_ws\": max(1.5, min(4.0, base_wind * 0.3 + np.random.uniform(0.5, 1.5))),\n",
    "        \"max_ws\": max(8.0, min(25.0, base_wind * 1.8 + np.random.uniform(2, 5))),\n",
    "        \"mean_temp\": 15 - (lat - 35) * 0.5 + np.random.uniform(-3, 3),\n",
    "        \"dominant_dir\": np.random.choice([45, 90, 135, 180, 225, 270])\n",
    "    }\n",
    "\n",
    "api_key = \"8afocaVgcfaIY5IPy5MKiUsRjJLy4Z6hSkAzFmTV\"\n",
    "\n",
    "print(\"\\nüå¨Ô∏è  Fetching wind data...\")\n",
    "features = []\n",
    "api_success_count = 0\n",
    "use_synthetic = False\n",
    "\n",
    "# Try first location to test API\n",
    "if len(turbines) > 0:\n",
    "    test_row = turbines.iloc[0]\n",
    "    test_feature = get_wind_features(test_row.ylat, test_row.xlong, api_key)\n",
    "    if test_feature is None:\n",
    "        print(\"‚ö†Ô∏è  NREL API unavailable - using synthetic wind data for demonstration\")\n",
    "        use_synthetic = True\n",
    "    else:\n",
    "        print(\"‚úì NREL API accessible - fetching real wind data\")\n",
    "\n",
    "# Fetch features for all turbines\n",
    "for i, row in turbines.iterrows():\n",
    "    if use_synthetic:\n",
    "        f = generate_synthetic_wind_features(row.ylat, row.xlong)\n",
    "    else:\n",
    "        f = get_wind_features(row.ylat, row.xlong, api_key)\n",
    "        if f:\n",
    "            api_success_count += 1\n",
    "        else:\n",
    "            # Fallback to synthetic if API fails\n",
    "            f = generate_synthetic_wind_features(row.ylat, row.xlong)\n",
    "    \n",
    "    if f:\n",
    "        features.append(f)\n",
    "    \n",
    "    if (i + 1) % 10 == 0 or i == len(turbines) - 1:\n",
    "        print(f\"  Progress: {i+1}/{len(turbines)} turbines processed\")\n",
    "\n",
    "wind_df = pd.DataFrame(features)\n",
    "data = pd.concat([turbines, wind_df], axis=1).dropna()\n",
    "print(f\"‚úì Wind features generated for {len(data)} turbines\")\n",
    "if not use_synthetic and api_success_count > 0:\n",
    "    print(f\"  ({api_success_count} from real API, {len(features) - api_success_count} synthetic)\")\n",
    "\n",
    "# 4Ô∏è‚É£ Spatial feature: distance to nearest other turbine (km)\n",
    "def nearest_neighbor_dist(lat, lon, df):\n",
    "    coords = df[['ylat','xlong']].values\n",
    "    dists = [distance((lat, lon), (y, x)).km for y, x in coords]\n",
    "    return np.sort(dists)[1]  # skip self (0)\n",
    "data[\"nearest_turbine_km\"] = [\n",
    "    nearest_neighbor_dist(r.ylat, r.xlong, turbines) for _, r in data.iterrows()\n",
    "]\n",
    "\n",
    "# 5Ô∏è‚É£ Label: simplified energy proxy (wind power density ‚àù v^3)\n",
    "data[\"power_proxy\"] = data[\"mean_ws\"] ** 3\n",
    "\n",
    "# 6Ô∏è‚É£ Train ML model\n",
    "print(\"\\nü§ñ Training Random Forest model...\")\n",
    "X = data[[\"mean_ws\",\"std_ws\",\"max_ws\",\"mean_temp\",\"nearest_turbine_km\"]]\n",
    "y = data[\"power_proxy\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "r2_score = model.score(X_test, y_test)\n",
    "print(f\"‚úì Model trained successfully!\")\n",
    "print(f\"  R¬≤ score on test set: {r2_score:.4f}\")\n",
    "\n",
    "# 7Ô∏è‚É£ Predict new candidate site\n",
    "print(\"\\nüéØ Predicting power potential for candidate site (Texas)...\")\n",
    "candidate_lat, candidate_lon = 31.9686, -99.9018\n",
    "\n",
    "if use_synthetic:\n",
    "    candidate = generate_synthetic_wind_features(candidate_lat, candidate_lon)\n",
    "else:\n",
    "    candidate = get_wind_features(candidate_lat, candidate_lon, api_key)\n",
    "    if candidate is None:\n",
    "        print(\"  API unavailable for candidate site, using synthetic data\")\n",
    "        candidate = generate_synthetic_wind_features(candidate_lat, candidate_lon)\n",
    "\n",
    "X_new = pd.DataFrame([{\n",
    "    \"mean_ws\": candidate[\"mean_ws\"],\n",
    "    \"std_ws\": candidate[\"std_ws\"],\n",
    "    \"max_ws\": candidate[\"max_ws\"],\n",
    "    \"mean_temp\": candidate[\"mean_temp\"],\n",
    "    \"nearest_turbine_km\": 20  # assume sparse area\n",
    "}])\n",
    "pred = model.predict(X_new)\n",
    "print(f\"‚úì Predicted power potential: {pred[0]:.2f} (m¬≥/s¬≥)\")\n",
    "print(f\"  Wind speed: {candidate['mean_ws']:.2f} m/s\")\n",
    "print(f\"  Location: ({candidate_lat}, {candidate_lon})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7722ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8Ô∏è‚É£ FIND OPTIMAL LOCATIONS FOR NEW WIND TURBINES\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéØ FINDING OPTIMAL WIND TURBINE LOCATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define search region (Texas in this example)\n",
    "# You can modify these bounds for any region\n",
    "lat_min, lat_max = 26.0, 36.5  # Texas latitude range\n",
    "lon_min, lon_max = -106.5, -93.5  # Texas longitude range\n",
    "\n",
    "# Create grid of candidate locations\n",
    "grid_resolution = 50  # Number of points in each dimension\n",
    "print(f\"\\nüìç Evaluating {grid_resolution}x{grid_resolution} = {grid_resolution**2} candidate locations...\")\n",
    "\n",
    "lat_grid = np.linspace(lat_min, lat_max, grid_resolution)\n",
    "lon_grid = np.linspace(lon_min, lon_max, grid_resolution)\n",
    "\n",
    "# Evaluate each location\n",
    "candidates = []\n",
    "predictions = []\n",
    "\n",
    "for i, lat in enumerate(lat_grid):\n",
    "    for lon in lon_grid:\n",
    "        # Get wind features for this location\n",
    "        if use_synthetic:\n",
    "            wind_data = generate_synthetic_wind_features(lat, lon)\n",
    "        else:\n",
    "            wind_data = get_wind_features(lat, lon, api_key)\n",
    "            if wind_data is None:\n",
    "                wind_data = generate_synthetic_wind_features(lat, lon)\n",
    "        \n",
    "        # Calculate distance to nearest existing turbine\n",
    "        if len(turbines) > 0:\n",
    "            min_dist = min([distance((lat, lon), (t_lat, t_lon)).km \n",
    "                           for t_lat, t_lon in zip(turbines['ylat'], turbines['xlong'])])\n",
    "        else:\n",
    "            min_dist = 50  # Default if no existing turbines\n",
    "        \n",
    "        # Create feature vector\n",
    "        features = {\n",
    "            \"mean_ws\": wind_data[\"mean_ws\"],\n",
    "            \"std_ws\": wind_data[\"std_ws\"],\n",
    "            \"max_ws\": wind_data[\"max_ws\"],\n",
    "            \"mean_temp\": wind_data[\"mean_temp\"],\n",
    "            \"nearest_turbine_km\": min_dist\n",
    "        }\n",
    "        \n",
    "        # Predict power potential\n",
    "        X_candidate = pd.DataFrame([features])\n",
    "        power_pred = model.predict(X_candidate)[0]\n",
    "        \n",
    "        candidates.append({\n",
    "            'lat': lat,\n",
    "            'lon': lon,\n",
    "            'power_potential': power_pred,\n",
    "            'mean_wind_speed': wind_data[\"mean_ws\"],\n",
    "            'nearest_turbine_km': min_dist\n",
    "        })\n",
    "        predictions.append(power_pred)\n",
    "    \n",
    "    # Progress update\n",
    "    if (i + 1) % 10 == 0 or i == len(lat_grid) - 1:\n",
    "        print(f\"  Progress: {((i+1)*grid_resolution)}/{grid_resolution**2} locations evaluated\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(candidates)\n",
    "\n",
    "# Find top 10 locations\n",
    "top_n = 10\n",
    "top_locations = results_df.nlargest(top_n, 'power_potential')\n",
    "\n",
    "print(f\"\\n‚úÖ Analysis complete!\")\n",
    "print(f\"\\nüèÜ TOP {top_n} OPTIMAL LOCATIONS FOR WIND TURBINES:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for idx, (i, row) in enumerate(top_locations.iterrows(), 1):\n",
    "    print(f\"\\n#{idx}:\")\n",
    "    print(f\"  üìç Location: ({row['lat']:.4f}, {row['lon']:.4f})\")\n",
    "    print(f\"  ‚ö° Power Potential: {row['power_potential']:.2f} (m¬≥/s¬≥)\")\n",
    "    print(f\"  üí® Mean Wind Speed: {row['mean_wind_speed']:.2f} m/s\")\n",
    "    print(f\"  üìè Distance to Nearest Turbine: {row['nearest_turbine_km']:.1f} km\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nüìä SUMMARY STATISTICS:\")\n",
    "print(f\"  Average power potential: {results_df['power_potential'].mean():.2f}\")\n",
    "print(f\"  Best location potential: {results_df['power_potential'].max():.2f}\")\n",
    "print(f\"  Worst location potential: {results_df['power_potential'].min():.2f}\")\n",
    "print(f\"  Range: {results_df['power_potential'].max() - results_df['power_potential'].min():.2f}\")\n",
    "\n",
    "# Optimal zone identification\n",
    "high_potential = results_df[results_df['power_potential'] > results_df['power_potential'].quantile(0.9)]\n",
    "print(f\"\\nüéØ HIGH-POTENTIAL ZONE (top 10%):\")\n",
    "print(f\"  Number of locations: {len(high_potential)}\")\n",
    "print(f\"  Latitude range: {high_potential['lat'].min():.2f}¬∞ to {high_potential['lat'].max():.2f}¬∞\")\n",
    "print(f\"  Longitude range: {high_potential['lon'].min():.2f}¬∞ to {high_potential['lon'].max():.2f}¬∞\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a707a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9Ô∏è‚É£ VISUALIZE OPTIMAL LOCATIONS\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "print(\"\\nüìà Creating visualization...\")\n",
    "\n",
    "# Create figure with subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Reshape data for heatmap\n",
    "power_grid = np.array(results_df['power_potential'].values).reshape(grid_resolution, grid_resolution)\n",
    "\n",
    "# Plot 1: Power Potential Heatmap\n",
    "im1 = axes[0].imshow(power_grid, \n",
    "                      extent=[lon_min, lon_max, lat_min, lat_max],\n",
    "                      origin='lower',\n",
    "                      cmap='YlOrRd',\n",
    "                      aspect='auto')\n",
    "axes[0].set_xlabel('Longitude', fontsize=12)\n",
    "axes[0].set_ylabel('Latitude', fontsize=12)\n",
    "axes[0].set_title('Wind Power Potential Heatmap\\n(Texas Region)', fontsize=14, fontweight='bold')\n",
    "cbar1 = plt.colorbar(im1, ax=axes[0])\n",
    "cbar1.set_label('Power Potential (m¬≥/s¬≥)', fontsize=11)\n",
    "\n",
    "# Mark existing turbines\n",
    "if len(turbines) > 0:\n",
    "    axes[0].scatter(turbines['xlong'], turbines['ylat'], \n",
    "                   c='blue', s=30, alpha=0.6, marker='o', \n",
    "                   label='Existing Turbines', edgecolors='darkblue', linewidth=0.5)\n",
    "\n",
    "# Mark top 10 optimal locations\n",
    "axes[0].scatter(top_locations['lon'], top_locations['lat'],\n",
    "               c='lime', s=200, alpha=0.9, marker='*',\n",
    "               label='Top 10 Optimal Sites', edgecolors='darkgreen', linewidth=2)\n",
    "\n",
    "# Mark the #1 location specially\n",
    "best = top_locations.iloc[0]\n",
    "axes[0].scatter(best['lon'], best['lat'],\n",
    "               c='white', s=300, alpha=1, marker='*',\n",
    "               edgecolors='black', linewidth=3, zorder=10)\n",
    "\n",
    "axes[0].legend(loc='upper right', fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "# Plot 2: Scatter plot - Wind Speed vs Power Potential\n",
    "scatter = axes[1].scatter(results_df['mean_wind_speed'], \n",
    "                          results_df['power_potential'],\n",
    "                          c=results_df['power_potential'],\n",
    "                          cmap='viridis',\n",
    "                          alpha=0.6,\n",
    "                          s=20)\n",
    "axes[1].set_xlabel('Mean Wind Speed (m/s)', fontsize=12)\n",
    "axes[1].set_ylabel('Power Potential (m¬≥/s¬≥)', fontsize=12)\n",
    "axes[1].set_title('Wind Speed vs Power Potential', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "# Highlight top locations\n",
    "axes[1].scatter(top_locations['mean_wind_speed'], \n",
    "               top_locations['power_potential'],\n",
    "               c='red', s=100, alpha=0.8, marker='*',\n",
    "               edgecolors='darkred', linewidth=1,\n",
    "               label='Top 10 Sites')\n",
    "axes[1].legend(fontsize=10)\n",
    "\n",
    "cbar2 = plt.colorbar(scatter, ax=axes[1])\n",
    "cbar2.set_label('Power Potential (m¬≥/s¬≥)', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Visualization complete!\")\n",
    "print(f\"\\nüí° RECOMMENDATIONS:\")\n",
    "print(f\"  ‚Ä¢ Best single location: ({best['lat']:.4f}, {best['lon']:.4f})\")\n",
    "print(f\"  ‚Ä¢ Expected power potential: {best['power_potential']:.2f} m¬≥/s¬≥\")\n",
    "print(f\"  ‚Ä¢ Consider clustering turbines in the high-potential zone\")\n",
    "print(f\"  ‚Ä¢ Ensure minimum {results_df['nearest_turbine_km'].min():.1f} km spacing between turbines\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13327ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîü EXPORT RESULTS\n",
    "print(\"\\nüíæ Exporting results...\")\n",
    "\n",
    "# Export top locations to CSV\n",
    "output_file = 'optimal_wind_turbine_locations.csv'\n",
    "top_locations.to_csv(output_file, index=False)\n",
    "print(f\"‚úì Top {top_n} locations saved to: {output_file}\")\n",
    "\n",
    "# Also export all candidates for further analysis\n",
    "all_results_file = 'all_candidate_locations.csv'\n",
    "results_df.to_csv(all_results_file, index=False)\n",
    "print(f\"‚úì All {len(results_df)} candidate locations saved to: {all_results_file}\")\n",
    "\n",
    "# Create a summary report\n",
    "summary_file = 'wind_optimization_summary.txt'\n",
    "with open(summary_file, 'w') as f:\n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "    f.write(\"WIND TURBINE LOCATION OPTIMIZATION REPORT\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(f\"Analysis Date: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"Search Region: Texas ({lat_min}¬∞ to {lat_max}¬∞ N, {lon_min}¬∞ to {lon_max}¬∞ W)\\n\")\n",
    "    f.write(f\"Grid Resolution: {grid_resolution}x{grid_resolution} ({grid_resolution**2} locations evaluated)\\n\\n\")\n",
    "    \n",
    "    f.write(f\"TOP {top_n} OPTIMAL LOCATIONS:\\n\")\n",
    "    f.write(\"-\"*80 + \"\\n\")\n",
    "    for idx, (i, row) in enumerate(top_locations.iterrows(), 1):\n",
    "        f.write(f\"\\nRank #{idx}:\\n\")\n",
    "        f.write(f\"  Latitude:  {row['lat']:.6f}¬∞\\n\")\n",
    "        f.write(f\"  Longitude: {row['lon']:.6f}¬∞\\n\")\n",
    "        f.write(f\"  Power Potential: {row['power_potential']:.2f} m¬≥/s¬≥\\n\")\n",
    "        f.write(f\"  Mean Wind Speed: {row['mean_wind_speed']:.2f} m/s\\n\")\n",
    "        f.write(f\"  Distance to Nearest Turbine: {row['nearest_turbine_km']:.1f} km\\n\")\n",
    "    \n",
    "    f.write(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    f.write(\"STATISTICAL SUMMARY\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "    f.write(f\"Average Power Potential: {results_df['power_potential'].mean():.2f} m¬≥/s¬≥\\n\")\n",
    "    f.write(f\"Maximum Power Potential: {results_df['power_potential'].max():.2f} m¬≥/s¬≥\\n\")\n",
    "    f.write(f\"Minimum Power Potential: {results_df['power_potential'].min():.2f} m¬≥/s¬≥\\n\")\n",
    "    f.write(f\"Standard Deviation: {results_df['power_potential'].std():.2f} m¬≥/s¬≥\\n\\n\")\n",
    "    \n",
    "    f.write(\"HIGH-POTENTIAL ZONE (Top 10%):\\n\")\n",
    "    f.write(f\"  Number of Sites: {len(high_potential)}\\n\")\n",
    "    f.write(f\"  Latitude Range: {high_potential['lat'].min():.4f}¬∞ to {high_potential['lat'].max():.4f}¬∞\\n\")\n",
    "    f.write(f\"  Longitude Range: {high_potential['lon'].min():.4f}¬∞ to {high_potential['lon'].max():.4f}¬∞\\n\")\n",
    "    f.write(f\"  Average Power Potential: {high_potential['power_potential'].mean():.2f} m¬≥/s¬≥\\n\")\n",
    "\n",
    "print(f\"‚úì Summary report saved to: {summary_file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ WIND TURBINE OPTIMIZATION COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nGenerated Files:\")\n",
    "print(f\"  1. {output_file} - Top {top_n} locations with coordinates\")\n",
    "print(f\"  2. {all_results_file} - All evaluated locations\")\n",
    "print(f\"  3. {summary_file} - Detailed text report\")\n",
    "print(\"\\nüí° Next Steps:\")\n",
    "print(\"  ‚Ä¢ Review the heatmap to identify optimal zones\")\n",
    "print(\"  ‚Ä¢ Consider environmental and regulatory constraints\")\n",
    "print(\"  ‚Ä¢ Perform on-site wind measurements at top locations\")\n",
    "print(\"  ‚Ä¢ Conduct economic feasibility analysis\")\n",
    "print(\"  ‚Ä¢ Evaluate grid connection availability\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37884000",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e435c7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [{\"inputs\":{\"body\":{}, params:{}, query:{\"lat\":\"35.22\", lon:\"-97.44\", names:\"2014\", hubheight:\"100\", timestep:\"60\", attributes:\"wind_speed, wind_direction, temperature\"}}, metadata:{\"version\":\"2.0.0\"}, status:400, errors:[\"The required 'email' parameter must be a valid email address\", The required 'wkt' or 'location_ids' must be a string or any array of integers respectively]}]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests, pandas as pd, io\n",
    "\n",
    "url = \"https://developer.nrel.gov/api/wind-toolkit/v2/wind/wtk-download.csv\"\n",
    "params = {\n",
    "    \"api_key\": \"8afocaVgcfaIY5IPy5MKiUsRjJLy4Z6hSkAzFmTV\",\n",
    "    \"lat\": 35.22,\n",
    "    \"lon\": -97.44,\n",
    "    \"names\": 2014,\n",
    "    \"hubheight\": 100,\n",
    "    \"timestep\": 60,\n",
    "    \"attributes\": \"wind_speed,wind_direction,temperature\"\n",
    "}\n",
    "r = requests.get(url, params=params)\n",
    "df = pd.read_csv(io.StringIO(r.text))\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
